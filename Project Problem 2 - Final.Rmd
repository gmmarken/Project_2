---
title: "Project Problem 2"
output: html_document
---

```{r}
#Problem description, objective, & description
print("We are attempting to predict if a person is likely to have be a high risk when we lend them money.

We are analyzing a data set with over 30,000 entries of previous customers and their risk level for Stark Enterprises. We are building a decision tree with that data and using it for our predictions. 

This data comprises dozens of variables about previous customers who applied for credit. We narrowed the variables down to a small handful we thought would be useful. We chose CNT_CHILDREN, AMT_INCOME_TOTAL, AMT_CREDIT, AMT_ANNUITY,AMT_GOODS_PRICE, and DAYS_EMPLOYED as our variables.")
```


```{r}
#load in libraries
library(rpart)
library(rpart.plot)
library(forecast)
library(tidyr)
library(caret)
library(ROSE)
```

```{r}
#load in data and view column names
cred <- read.csv("credit_8.csv", header = TRUE)
names(cred)
```

```{r}
#drop null values from dataset
cred <- drop_na(cred)
```

```{r}
#general exploration of data
head(cred,10)
str(cred)
```

```{r}
# Choosing to only keep columns that seem like they're good predictors
cred <- cred[ , c(3, 8:12, 19)]
names(cred)
```

```{r}
#set seed
set.seed(1331)
```

```{r}
#training-validation split of 60-40
train_index <-sample(1:nrow(cred), 0.6*nrow(cred))
valid_index <-setdiff(1:nrow(cred), train_index)
```

```{r}
#create data frames with new indices
train_df <- cred[train_index, ]
valid_df <- cred[valid_index, ]
```

```{r}
#check split results
nrow(train_df)
nrow(valid_df)
```

```{r}
#Balancing data
train_df$TARGET <- as.factor(train_df$TARGET)
train_df_balanced <- ROSE(TARGET ~  CNT_CHILDREN 
                          + AMT_INCOME_TOTAL + AMT_CREDIT 
                          + AMT_ANNUITY 
                          + AMT_GOODS_PRICE 
                          + DAYS_EMPLOYED,
                          data = train_df, seed = 1331)$data
```

```{r}
#check balancing results
table(train_df_balanced$TARGET)
```

```{r}
#Classification tree
class_tr <- rpart(TARGET ~ CNT_CHILDREN 
                  + AMT_INCOME_TOTAL + AMT_CREDIT 
                  + AMT_ANNUITY 
                  + AMT_GOODS_PRICE 
                  + DAYS_EMPLOYED,
                  data = train_df_balanced, method = "class", maxdepth = 20)
prp(class_tr)
```
```{r}
#clean plot of classification tree
rpart.plot(class_tr, type = 5)
rpart.rules(class_tr, extra = 4)
```
```{r}
#ensure data frames are the same classifications
library(janitor)
valid_df$TARGET <- as.factor(valid_df$TARGET)
compare_df_cols(train_df,valid_df)
```

```{r}
#Confusion matrix - training dataframe
class_tr_train_predict <- predict(class_tr, train_df_balanced,
                                  type = "class")
confusionMatrix(class_tr_train_predict, train_df_balanced$TARGET,
                positive = "1")
```

```{r}
#confusion matrix - validation dataframe
class_tr_valid_predict <- predict(class_tr, valid_df,
                                  type = "class")

confusionMatrix(class_tr_valid_predict, valid_df$TARGET,
                positive = "1")
```

```{r}
#Probabilities
class_tr_valid_predict_prob <- predict(class_tr, valid_df,
                                       type = "prob")
head(class_tr_valid_predict_prob)
```

```{r}
# Implementing new records
new_record_class <- data.frame(CNT_CHILDREN = 0,
                               AMT_INCOME_TOTAL = 180000,
                               AMT_CREDIT = 383760, 
                               AMT_ANNUITY = 40428, 
                               AMT_GOODS_PRICE = 360000, 
                               DAYS_EMPLOYED = -1304)
class_tr1 <- predict(class_tr, newdata = new_record_class)

new_record_class2 <- data.frame(CNT_CHILDREN = 0,
                               AMT_INCOME_TOTAL = 292500,
                               AMT_CREDIT = 675000, 
                               AMT_ANNUITY = 24376.5, 
                               AMT_GOODS_PRICE = 675000, 
                               DAYS_EMPLOYED = -1548)
class_tr2 <- predict(class_tr, newdata = new_record_class2)

new_record_class3 <- data.frame(CNT_CHILDREN = 0,
                               AMT_INCOME_TOTAL = 157500,
                               AMT_CREDIT = 761067, 
                               AMT_ANNUITY = 33655.5, 
                               AMT_GOODS_PRICE = 657000, 
                               DAYS_EMPLOYED = -2124)
class_tr3 <- predict(class_tr, newdata = new_record_class3)

new_record_class4 <- data.frame(CNT_CHILDREN = 0,
                               AMT_INCOME_TOTAL = 90000,
                               AMT_CREDIT = 67500, 
                               AMT_ANNUITY = 7047, 
                               AMT_GOODS_PRICE = 67500, 
                               DAYS_EMPLOYED = 365243)
class_tr4 <- predict(class_tr, newdata = new_record_class4)

new_record_class5 <- data.frame(CNT_CHILDREN = 3,
                               AMT_INCOME_TOTAL = 135000,
                               AMT_CREDIT = 301464, 
                               AMT_ANNUITY = 20277, 
                               AMT_GOODS_PRICE = 238500, 
                               DAYS_EMPLOYED = -989)
class_tr5 <- predict(class_tr, newdata = new_record_class5)

class_tr1
class_tr2
class_tr3
class_tr4
class_tr5
```

```{r}
#Final model discussion
print("As you can see, we have 5 predictions, one for each of our new records. We think our model is solid and accurate with it's predictions. It's also very informative and allows us to make good analytical recommendations to Stark Enterprises.
      
The accuracy of the training model was 0.5728 and the validation model's accuracy was 0.6838. We are confident in these numbers as our training and validation models are close in their accuracies. While the accuracy is not the highest, we believe that it allows us to make realistic predictions for determining risk. At the very least, our accuracy is greater than .50 which allows us more confidence than merely guessing.") 
```

